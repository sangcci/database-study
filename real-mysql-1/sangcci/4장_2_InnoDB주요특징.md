# InnoDB 주요 특징
![image](https://github.com/user-attachments/assets/a90aa79e-28fd-4b98-a170-c2c5fb0570e7)

## 프라이머리 키에 의한 클러스터링

`PRIMARY KEY` 값이 순서대로 저장된다.
모든 `SECONDARY INDEX`는 실제 레코드 주소가 아닌, `PRIMARY KEY`값을 논리적인 주소로 사용한다. 이 때문에 클러스터링 인덱스인 `PRIMARY KEY`를 이용한 레인지 스캔은 상당히 빨리 처리된다고 한다. 
쿼리 실행계획도 다른 보조 인덱스보다 우선순위가 높다고 한다.

이와 관련해서는 인덱스 부분에서 자세히 공부할 예정.

## 외래 키 지원

테이블 사이의 관계를 나타내주는 외래 키를 지원한다.

하지만 다음과 같은 단점이 존재하기 때문에 주의해서 사용해야 한다고 함.
> - 부모 테이블, 자식 테이블 모두 해당 칼럼에 인덱스 생성
> - 키 데이터 변경 시, 부모 혹은 자식 테이블에도 데이터가 있는지 체크하는 작업 필요 -> 잠금이 테이블에 전파 -> 데드락 자주 발생

이런 경우 직접 `foreign_key_checks`를 OFF로 바꾸고 작업한다고 한다. 자세한 것은 해당 키워드를 검색해보자.

그래서 데이터베이스 설계에 외래키를 아예 사용하지 않는 경우도 있다고 한다.

## MVCC; Multi Version Concurrency Control

레코드 레벨의 트랜잭션 지원
잠금을 사용하지 않는 일관된 읽기 제공.

이 모든 건 `undo log`라는 메모리 공간을 만듬으로써 발생
![image](https://github.com/user-attachments/assets/74b7c815-b9f1-409e-bc76-441fb83ea658)

```sql
insert into member (m_id, m_name, m_area)
values (12, '홍길동', '서울');
commit;

update member set m_area = '경기'
where m_id = 12;
```

만일 `commit`이나 `rollback`을 안한 상태에서,
```
select * from member where m_id = 12;
```
조회 쿼리를 날려버리면 둘 중 어떤 곳을 조회할까?

-> MySQL 서버의 `transaction_isolation`에 설정된 트랜잭션 격리 수준에 따라 다르다.

`read_uncommitted`같은 경우는 변경된 데이터인 innodb 데이터 풀에서 가져올 것이고, 이보다 더 수준 높은 격리 수준은 undo 영역의 데이터를 반환할 것이다.
이를 MVCC라고 한다. 하나의 레코드에 2개의 버전이 유지가 된다. **물론 버전은 상황에 따라 무한이 많아질 수 있다.**
다음 상황을 보자.

```sql
CREATE TABLE products ( 
	id INT PRIMARY KEY, 
	name VARCHAR(100),
	price DECIMAL(10, 2) 
);
```
`products`라는 테이블을 만들었다고 가정하고, T1 트랜잭션은 `products`의 레코드 1개를 조회하고, 나머지 T2, T3, T4... 트랜잭션들은 T1이 조회한 레코드를 계속 수정하는 상황이다.
```sql
# T1
START TRANSACTION; 
SELECT * FROM products WHERE id = 1;
# 아직 commit 안한 상태
```

```sql
# T2, T3, T4... 
START TRANSACTION; 
UPDATE products SET price = price * 1.1 WHERE id = 1; 
COMMIT;
```
T1 트랜잭션이 길어지면 길어질수록, T2, T3, T4... 트랜잭션들이 수정하고 commit할 때 마다 T1 트랜잭션을 위한 새로운 버전들이 쌓이게 된다.

그렇다면, T1 트랜잭션의 시작 시점에 있던 이전 값만 저장하면 되는데, 왜 T2, T3, T4... 각 트랜잭션들은 이전 값들을 계속 저장하는걸까? T1이 시작한 이후로 가장 먼저 실행된 T2의 이전 값만 저장하면 되지 않을까?

우선, 각각의 이전 버전이 있어야 T1의 시점에서의 이전 값을 찾을 수 있다. LinkedList 자료구조를 생각해보자. 멀리 있는 값을 바로 찾을 수 없고, 바로 다음 node로 계속 타고타고 이동해야 한다.
마찬가지로, 이전 버전까지 계속 타고타고 가야하는 구조이다.
```
버전 체인 (Version Chain):

InnoDB는 각 레코드에 대해 Hidden Column을 사용하여 Roll Pointer를 저장합니다. 이 Roll Pointer는 해당 레코드의 이전 버전이 저장된 Undo Log를 가리킵니다. 즉, 레코드의 현재 버전에서 시작하여 이전 버전으로 거슬러 올라가면, Undo Log에 기록된 과거의 모든 상태를 따라갈 수 있습니다.

이러한 구조는 Linked List의 노드들이 서로 연결된 것과 유사합니다. 레코드의 각 버전은 이전 버전을 가리키는 포인터(링크)를 가지고 있어, 특정 트랜잭션의 스냅샷을 재구성할 수 있게 됩니다.

- gpt
```

그리고 제일 중요한 건, 각 T2, T3, T4...마다 **롤백이 발생할 가능성이 있기 때문에 무조건 저장한다.**

이는 트랜잭션 격리수준에 영향을 많이 미친다는 것을 알고 있자.

만일 rollback하게되면, 백업되어있던 undo log에 있는 데이터를 다시 innodb 버퍼 풀에 복구하고, undo log에 있던 데이터는 필요로 하는 트랜잭션이 없을 때 삭제된다.

> Multi Version Concurrency Control
> 멀티 버전. 버전 여러개 관리.

---

## 잠금 없는 일관된 읽기; Non-Locking Consistent Read
![image](https://github.com/user-attachments/assets/bedb7afc-32b8-4d45-9420-411db0e63bc0)

innodb 엔진은 위에서 설명한 MVCC 기술(undo log를 활용한 기술)을 이용하여, **잠금 없이도 읽기 작업을 수행할 수 있다.**
가장 엄격한 격리 수준인 `SERIALIZABLE`이 아닌 이상, `SELECT` 작업은 다른 트랜잭션이 변경하고 있어도 그냥 **바로 실행된다.**
`READ_UNCOMMITTED` 수준은, undo 로그도 사용하지 않고 그냥 바로 값을 가져오고, 나머지 두 수준은 undo 로그에서 가져온다. 3개 다 잠금은 일어나지 않음을 알 수 있다.

트랜잭션을 오래 끌면?
> `select`를 오래 끌어버리면, 잠금 없는 일관된 읽기 때문에 undo log를 삭제하지 못하고 계속 유지하기 때문에 MySQL서버가 느려지거나 문제 발생할 수 있다.

이는 위의 T1과 T2, T3, T4... 예제에도 자세히 나와있다.

---

## 자동 데드락 감지

> 내부적으로 잠금이 교착 상태에 빠지지 않았는지 체크하기 위해 잠금 대기 목록을 그래프(wait-for list) 형태로 관리.

데드락 감지 스레드가 주기적으로 잠금 대기 그래프를 검사한다. 그 중에서 **잠금이 길게 이어지는 트랜잭션(교착 상태)** 을 찾아서, 그 중 하나를 강제 종료한다.

어느 트랜잭션을 먼저 종료할 것인지는 'undo log의 양'으로 판단한다. 그 중 undo log의 양이 많은 트랜잭션을 강제 종료시키고, 나머지는 강제 롤백시킨다.
이는 undo 처리를 해야 할 내용이 적어 서버 부하가 덜 발생하기 때문이다.

tip
> `innodb_table_locks` 시스템 변수 활성화

innodb 엔진은 상위 레이블인 mysql 엔진에서 관리되는 테이블 잠금(`LOCK TABLES` 명령으로 잠긴 테이블)은 볼 수 없어서 데드락 감지가 불확실. 그래서 해당 시스템 변수를 활성화시켜 테이블 레벨의 잠금까지 감지하도록 하자.

tip2
> innodb_deadlock_detect

동시 처리 스레드가 매우 많아지거나 각 트랜잭션이 가진 잠금의 개수가 많아지면 그만큼 데드락 감지 스레드가 느려지게 된다.
데드락 감지 스레드가 작동할 때, wait-for list 테이블을 감지해야 하기 때문에 감지하는 동안 잠금 상태가 변경되지 않도록 여기에도 잠금을 건다. 그러면 데드락 감지의 작동이 느려지며, 서비스 쿼리 처리하는 스레드도 연쇄적으로 느려지게 된다.

이러한 상황에서 `innodb_deadlock_detect`를 비활성화시켜 데드락 감지 스레드를 작동시키지 않게 할 수 있다. 그 후 `innodb_lock_wait_timeout` 시스템 변수를 활성화하여 일정 시간이 지나면 자동으로 요청이 실패하고 에러 메세지를 반환하도록 설정한다. `innodb_deadlock_detect`를 OFF한다면, `innodb_lock_wait_timeout`을 기본값인 50초보다 훨씬 낮은 시간으로 변경해서 사용할 것을 권장한다고 한다.

여담으로, 구글에서 PK기반의 조회 변경이 높은 빈도로 실행되었는데, 이 때 데드락 감지 스레드로 인해 성능 저하 이슈를 발견하여 데드락 감지 스레드를 활성화 혹은 비활성화시킬 수 있는 기능을 자체 개발해서 사용하고, 오라클에 기능 추가를 요청해서 해당 기능이 추가된 것이라고 한다.
그래서 PK기반의 조회 또는 `secondary index`를 기반으로 높은 동시성 처리를 요구하는 서비스가 있다면 비활성화 시켜 성능 비교를 해보는 것을 추천한다고 한다.

---

## 자동화된 장애 복구

innodb는 매우 견고해서 데이터 파일 손상, MySQL 서버 이슈로 시작되지 못하는 경우는 거의 없다고 한다.
MySQL 서버는 시작할 때 '완료되지 못한 트랜잭션', '디스크에 일부만 기록된 데이터 페이지' 등에 대한 일련의 복구 작업이 자동으로 진행된다.

하지만 MySQL 서버와 무관하게 disk, 서버 하드웨어 이슈로 인해 innoDB 스토리지 엔진이 자동으로 복구를 못 하는 경우가 발생할 수 있는데, 이는 복구하기 쉽지 않다고 한다.

이와 관련된 시스템 변수는 `innodb_force_recovery`이며, MySQL 매뉴얼 및 Real My SQL 4장에서 참고하자.

---

## Innodb 버퍼 풀

가장 핵심적인 부분이다.
1. 디스크 데이터 파일이나, 인덱스 정보를 디스크 혹은 **메모리에 캐시**해둔다.
2. 쓰기 작업을 지연시켜 일괄 작업으로 처리할 수 있게 해주는 버퍼 역할을 한다.
	이를 통해 랜덤 디스크 작업(이곳저곳에 위치한 레코드 변경)의 횟수를 줄일 수 있다.

버퍼 풀은 기본적으로 여러 개의 작은 단위로 분리되서 운영된다. 이렇게 분리된 버퍼들을 버퍼 풀 인스턴스라 불리며, `innodb_buffer_poll_instances` 시스템 변수를 통해 개수를 알아낼 수 있다.


tip
> 버퍼 풀의 크기를 서버에 맞게 적절히 설정하는 방법

운영체제와 클라이언트 스레드가 사용할 메모리도 충분히 고려해야 한다. 또한 레코드 버퍼 용도로 사용되는 메모리가 많이 필요할 수도 있다.
그래서 버퍼 풀의 크기를 무작정 늘리는 것이 무조건 좋지 않다.

그래서 MySQL의 메뉴얼 및 real my sql 책을 충분히 숙지한 후 건드리는 것이 좋다.

버퍼 풀의 크기는 128MB를 기준으로 늘리고 줄일 수 있다.

### 페이지

> 쿼리 정보가 아니라, 레코드가 저장됨. 여러개의 레코드가 포함될 수 있다.

![image](https://github.com/user-attachments/assets/5b59b1ec-2015-4557-9c57-2853f666c5ec)

클러스터형 인덱스의 Data page이다. 

### 버퍼 풀의 구조

버퍼 풀은 페이지 크기로 쪼개서 관리된다.
한 페이지는 여러개의 레코드를 저장할 수 있다.

그래서 해당 페이지를 관리하기 위해 3가지 자료구조로 관리한다.
1. LRU 리스트
2. 플러시 리스트
3. 프리 리스트
이들 모두 버퍼 이며, `Queue`가 아닌 `LinkedList`자료구조를 사용하는데, 이 들 요소 하나하나는 페이지이며, 페이지를 리스트로 목록화하여 관리하는 것을 알 수 있다.

자바의 `LinkedList`를 생각해보자.
리스트에 자료를 넣으면, 해당 자료는 메모리에 저장된다. 메모리에 저장될 때 순서대로 저장되는가? 그냥 heap 영역 내부에 랜덤한 공간에 할당된다. 그 후 해당 메모리에 있는 위치인 주소 값을 가져와서 배열 혹은 구조체에 저장한다.
`LinkedList`는 구조체 형태로 이루어져 있어, 바로 이전 혹은 바로 다음 연결 노드의 주소만 알고 있다. 
그래서 위 innodb 구조 그림에서도 버퍼 풀을 네모 칸으로 표현하여 순서가 존재하는 것처럼 인식할 수 있는데, 단순히 페이지 단위로 나눠서 관리한다는 의미이며, 랜덤 위치에 저장되는 것을 알고 있자.

이 개념을 이해하고 넘어가면 좀 더 떠올리기 쉬울 것이다.

그럼 이어서 하나하나 자세히 알아보자.


프리 리스트; Free List

우선, MySQL이 시작될 때 버퍼 풀은
페이지라는 단위로 메모리 공간을 할당받고, 해당 페이지의 주소 값들을 리스트들이 관리한다.
그래서 버퍼 풀의 페이지는 아직 요청한 데이터가 없기 때문에 모두 비어있고, 이들은 프리 리스트에 추가된다.
새로운 데이터, 인덱스 페이지가 버퍼 풀에 로드 될 때 마다 비어있던 페이지를 가져와서 할당한다. 그래서 프리 리스트에서 해당 페이지는 제거되고 LRU 리스트에 추가된다.
사용하지 않는 페이지를 관리하는 용도.

LRU 리스트; Least Recently Used List
> LRU와 MRU를 합친 구조. 디스크로부터 한 번 읽어온 페이지를 최대한 오랫동안 메모리에 유지시켜 디스크 I/O를 최소화 하는 것이 목적
![image](https://github.com/user-attachments/assets/99f824f9-69ba-4bf6-8c31-d1d894386284)


운영체제의 페이지 교체 알고리즘 중 LRU 방식과 아예 동일하다. 그래서 기존에 운영체제를 공부했다면 쉽게 이해할 수 있다.

위 그림과 같이 `LinkedList`로 관리된다. 이 중 New 서브리스트는 MRU 리스트, Old 서브리스트는 LRU 리스트에 해당된다.

데이터 페이지는 사용자 쿼리가 얼마나 최근에 접근했었는지에 따라 '나이'가 부여된다. 데이터 페이지가 쿼리에 의해 사용되면 나이가 초기화되고 MRU 헤더 부분으로 이동한다. 그만큼 다른 페이지들은 리스트가 밀려나 나이가 오래된다.
LRU Tail 부분에서 밀려나면, 제거된다.

만일 데이터가 페이지에 없었다면, 디스크에서 데이터 페이지를 버퍼 풀에 적재하고, 해당 포인터(주소)를 LRU Head 부분으로 추가한다.

플러시 리스트; Flush List

> 디스크로 동기화되지 않은 데이터를 가진 데이터 페이지 = 더티 페이지
> 의 '변경 시점 기준' 페이지 목록을 관리한다.

`INSERT`, `UPDATE`, `DELETE` 등 Disk로 데이터를 업데이트 하는 주기를 줄여주는 쓰기 버퍼링의 핵심 구현 요소이다. 리두 로그와 같이 사용된다.

조회를 할 경우에는 LRU에서 관리되지만, 만일 데이터의 변경이 발생했다면, 해당 페이지는 플러시 리스트로 옮겨져서 관리된다.

![image](https://github.com/user-attachments/assets/21e4757e-0847-4e9f-a584-800c6540f23b)

플러시 리스트에 저장된 데이터 페이지들을 Disk로 업데이트 하는 작업을 체크 포인트 이벤트를 통해 이루어진다.

체크포인트 이벤트 발생 시 리두 로그에 저장된 데이터 페이지를 Disk로 업데이트 한다. 리두 로그의 각 요소들은 실제로 플러시 리스트에 있는 데이터 페이지들을 가리키고 있다. 
그래서 버퍼 풀의 용량이 아무리 많아도 리두 로그의 크기가 작다면, 그만큼 자주 체크포인트 이벤트가 발생한다는 의미이므로 쓰기 버퍼링의 효과를 제대로 못누리고 있는 셈이다.

### 리두 로그; redo log
> 데이터베이스의 비정상 종료가 발생했을 때, 트랜잭션의 지속성을 보장하기 위해 사용

바이너리 파일로 되어있어 사람이 이해하기 어렵지만, 고유한 형식을 따름.
- LSN: 로그 레코드가 기록된 순서를 나타냄
- Type: 로그 레코드의 유형을 나타냄. `데이터 변경`, `인덱스 수정`, `트랜잭션 종료` 등..
- Data: 실제 변경된 데이터 내용 포함.

![image](https://github.com/user-attachments/assets/5082d0a1-3835-4f46-a67a-a97da04477b5)

트랜잭션이 발생하면,
1. 트랜잭션 시작 
2. 변경 쿼리로 인해 버퍼 풀에 기록, 이후 redo log에 변경 사항 기록
3. 트랜잭션 커밋 요청
4. 우선, redo log에 **==변경 사항을 Disk의 redo Log 파일로 flush==**
5. 트랜잭션 커밋 완료 처리, redo log에 커밋 완료를 기록 -> 이 때는 아직 변경 사항이 기록되지 않았을 수도 있음.
6. 이후 더티 페이지는 체크포인트 과정에서 백그라운드에서 실제 디스크 파일에 반영
> 중요한 점은, redo log라는 것은 메모리 상의 buffer 뿐만 아니라 '파일'형태로도 존재하며, disk에 저장된다는 점이다. 이점을 인지하고 있어야 위 순서를 이해할 수 있다.

여기서 만일, 비정상적으로 종료되었을 때, 
1. innodb는 redo log에 있는 기록들을 이용해 복구

체크 포인트가 발생하면,
1. 데이터 페이지를 디스크에 기록
2. redo log 파일에서 특정 지점까지 로그 삭제하여 공간 확보
이 작업은 데이터베이스 복구 보다는, redo log 공간 자체의 관리를 위해 제공됨.
백그라운드 쓰레드에서 발생. 우리가 직접 신경 쓸 필요는 없다.


### 버퍼 풀 플러시; buffer poll flush
2가지가 존재한다.

플러시 리스트 플러시
> 버퍼에 있는 데이터를 Disk에 반영하는 작업.

위에서 설명했다시피, 리두 로그를 주기적으로 공간을 비워야 한다.

그런데 반드시 플러시 리스트에 있는 더티 페이지가 먼저 디스크로 동기화 되어야 한다. 그 후에 리두 로그에 있는 데이터를 지운다.
그래서 InnoDB 엔진은 주기적으로 `Flush_list()`함수를 호출해서 플러시 리스트에서 오래전에 변경된 데이터 페이지를 순서대로 동기화하는 작업을 수행한다.

언제부터 얼마나 많은 더티 페이지를 한 번에 디스크로 기록하냐에 따라 성능차이가 달렸다.

이러한 성능을 제어하는 시스템 변수들을 제공하는데, 자세한 정보는 114p 플러시 리스트 플러시를 참고하자.

LRU 리스트 플러시
> 새로운 페이지들을 읽어올 공간을 만들기 위해 사용 빈도가 낮은 데이터 페이지를 제거하는 작업

### 버퍼 풀 상태 백업 및 복구
버퍼 풀도 백업하고 복구한다면, 처음 어플리케이션 시작할 때 속도가 굉장히 빨라진다. 이미 버퍼 풀에 준비되어 있어서 디스크에서 데이터를 읽지 않아도 쿼리가 처리가 될 수 있기 때문이다. 이를 워밍업(Warming Up)이라 한다.

이전에는 강제 워밍업을 위해서 서비스 전에 풀 스캔을 한 번씩 실행하고 오픈했다고 한다.
5.6 버전부터 버퍼 풀 덤프 및 적재 기능이 도입되고 위와 같은 작업 없이 명령어로 백업 및 복구할 수 있게 되었다.

이와 관련된 내용은 117p 4.2.7.5 버퍼 풀 상태 백업 및 복구를 살펴보자.

### 버퍼 풀의 적재 내용 확인
8.0 버전부터 부하에 영향을 끼치지 않으면서 버퍼 풀의 데이터 페이지가 얼마나 InnoDB 버퍼 풀에 적재되어 있는지 알 수 있다.

---

## Double Write Buffer

우선 리두 로그로 인해, 디스크와의 I/O를 줄인 쓰기 버퍼링의 효율을 체감했다.

하지만, 리두 로그안의 더티 페이지를 디스크 파일로 flush할 때 갑자기 운영체제나 하드웨어의 오작동으로인해(정전 등) 시스템이 비정상으로 종료되었을 경우 **일부분만 기록되는 문제**가 발생할 수 있다. 나머지 일부분은 그대로 날아갈 수 있어서 복구할 수 없을수도 있다.
이를 파셜 페이지(Partial-page), 톤 페이지(Torn-page)라고 부른다.

![image](https://github.com/user-attachments/assets/a6757544-92eb-4a3a-9449-4a026f1155a0)

1. 디스크로 flush하기 전에 더티 페이지 묶어서 DoubleWrite 버퍼에 기록
2. 페이지 1개씩 디스크에 flush

> redo log와 쓰임이 비슷하여 햇갈릴 수 있다. 

데이터 보호의 범위와 목적에 차이가 존재하나.

Double Write Buffer는 디스크 쓰기의 무결성을 보장한다.
Redo Log는 트랜잭션의 일관성을 유지한다.

**트랜잭션 안에서의 변경 요소**들만 일치시킨다면 redo log의 목적에 부합하지만, **페이지 전체를 안전하게 쓰기** 하려면 Double Write Buffer 등의 페이지 전체 복구 매커니즘이 필요하다.

한 트랜잭션 안에서 `INSERT`가 발생할 경우는 전체 페이지가 되겠지만, `UPDATE`일 경우 해당 페이지의 일부분만 수정하고, 그 부분만 redo log로 기록되기 때문에, 전체 페이지를 복구하는 매커니즘이 아니다.

사실상 redo log의 복구 매커니즘보다 좀 더 하위 레이어에 있다고 봐도 무방하다.

주로, 무결성이 매우 중요한 서비스일 경우 Double Writer 기능을 활성화하는 편이라고 한다. 디스크의 내부 동작에 따라 성능이 달라지는데 SSD일 경우 부담스럽다고 한다.

### 여러개 사본 유지
일반적으로는 MySQL 서버에서는 복제(Replication)를 이용하여 데이터에 대해 여러 사본을 유지한다. 그래서 비정상으로 종료될 때 백업, 바이너리 로그를 이용하여 동기화하려는 경우가 많다고 한다. 
그래서 DoubleWrite 뿐만 아니라 `redo log`, `복제 바이너리 log` 등 트랜잭션을 커밋하는 시점에 동기화할 것이 많다. 성능을 보며 기능을 차용할지 고민해봐야 한다.

---

## 언두 로그; Undo Log

> DML로 변경되기 이전 버전의 데이터를 별도로 백업

- 트랜잭션 롤백 대비용
- 잠금 없이 트랜잭션 격리수준 보장

### 리두 로그와의 관계
> redo log는 트랜잭션이 ==커밋==된 후에 비정상 종료 등으로 데이터베이스 복구할 때 사용하고, undo log는 트랜잭션이 ==롤백==되었을 때 이전 상태로 복구하는 용도이다.
![image](https://github.com/user-attachments/assets/6d91a98a-7dee-48ce-b488-5921b1fa2098)


트랜잭션이 롤백 되었을 때, 해당 트랜잭션이 커밋되었는지, 롤백되었는지, 실행 중간 상태였는지를 확인하기 위해 리두 로그를 활용한다.

### 언두 로그 모니터링링
#### undo log 공간이 급격하게 증가하는 경우
MySQL 5.5 이전 버전에서는 한 번 증가한 undo log는 다시 줄어들지 않아서, 대용량의 데이터를 처리할 때 1억 건의 레코드를 한 트랜잭션 안에서 `DELETE` 하려고 할 때, 레코드 한 건 마다 삭제 후 undo log에 삭제되기 전 값을 저장한다. 즉, 1억 건의 undo log 공간이 필요하다..

트랜잭션이 오랜 시간 동안 실행될 때도 undo log의 양은 급격하게 증가할 수 있다. 이에 대한 설명은 위에서 `Non-Locking Consistent Read`부분을 참고하자.

자주 변경되는 레코드를 조회하는 쿼리가 실행될 경우, undo log를 필요한 만큼 스캔해야만 필요한 레코드를 찾을 수 있기 때문에 해당 이슈는 성능에 상당한 영향을 미친다.

이런 문제를 MySQL 5.7, 8.0으로 업그레이드 되면서 해결되었다. 언두 로그를 이전 트랜잭션에서 사용한 공간을 재활용함으로써 디스크 공간을 줄이는 것도 가능하며, 서버에서 자체적으로 필요한 시점에 자동으로 줄여주기도 한다.

하지만 트랜잭션이 장시간 유지되는 것은 좋지 않기 때문에, 언두 로그의 급증 여부를 모니터링하는 것이 좋다고 한다.
```sql
# 언두 로그 건수 확인
SHOW ENGINE INNODB STATUS \G

# MySQL 8.0 버전에서 사용 가능한 명령
SELECT count
FROM information_schema.innodb_metrics
WHERE SUBSYSTEM='transaction' AND NAME='trx_rseg_history_len;
```

해당 로그는 2개로 관리된다.
- INSERT 언두 로그
- UPDATE&DELETE 언두 로그
INSERT는 MVCC에는 발생하지 않고(다른 트랜잭션이 레코드 존재를 몰라 SELECT 자체를 안함), UPDATE&DELETE에만 발생하기 때문이다.

### 언두 테이블스페이스 관리

> 언두 로그가 저장되는 공간을 undo tablespace라고 한다.

MySQL 5.6 이전 버전에서는 시스템 테이블스페이스에서 관리(`ibdata.ibd`)했고, MySQL 서버가 초기화될 때만 생성되었기 때문에 확장에 한계가 존재.

그래서 5.6 버전에서는 별도의 언두 로그 파일을 사용하는 기능이 추가되었고 둘 중 하나를 선택할 수 있었다.
그리고 8.0 버전부터는 **완전히 시스템 테이블스페이스 외부의 별도 로그 파일로 기록되도록 개선**되었다.

![image](https://github.com/user-attachments/assets/53b2530e-0e1f-4fca-9e97-fa29e8a9dc9a)

다음은 언두 로그 파일 테이블스페이스 내부 구조이다.

만일 하나의 트랜잭션에 `INSERT` 3개, `UPDATE` 2개를 수행한다면 총 5개의 undo 슬롯을 필요로 한다. 하나의 페이지 크기는 16KB이며 해당 페이지가 언두 슬롯에 배치된다.
```
최대 동시 트랜잭션 수 = (innoDB 페이지 크기) / (하나의 트랜잭션에 사용하는 undo log 크기)
```
일반적인 설정인 16KB innoDB의 기본값은, 16 * 1024 / 16 * 128 * 2 / 2 = 131072개의 트랜잭션을 동시에 처리한다고 한다. 일반적인 서비스는 이정도의 갯수가 동시에 발생하지 않으므로 기본값을 사용하자.

undo log 슬롯이 부족한 경우 트랜잭션을 시작할 수 없는 심각한 문제가 발생하기 때문에, 적절히 갯수를 맞춰야 한다.
이와 관련된 사항은 127p 4.2.9.2 언두 테이블스페이스 관리에서 찾아볼 수 있다.

---

## 체인지 버퍼

> 레코드가 `INSERT`, `UPDATE`될 때 해당 테이블에 포함된 인덱스 변경도 필요. 이 때 디스크에서 가져와야 한다면 즉시 실행하지 않고 change buffer에 보관 후 바로 반환.

마치 버퍼 풀의 쓰기 버퍼링과 매우 유사하다.

이들은 체인지 버퍼 머지 쓰레드라는 백그라운드 쓰레드에 의해 병합된다.

주의할 점은, 중복 여부를 체크해야 하는 `UNIQUE INDEX`의 경우는 체인지 버퍼를 사용할 수 없다.

이와 관련된 설정은 `innodb_change_buffering` 시스템 변수를 찾아보자. 자세한 설정은 129p 4.2.10 체인지 버퍼 파트에서 확인할 수 있다.

---

## 리두 로그 및 로그 버퍼

> 데이터를 잃지 않게 해주는 안전장치. ACID 중 Durable(영속성)과 가장 밀접하게 연결되어 있음.

- 커밋 이후 데이터 파일에 기록되었을 때
- 롤백 후에 데이터를 돌려보낼 때

### 리두 로그와 체크포인트 관계

사실 리두 로그가 없어도 버퍼 풀의 더티 페이지 수를 기반으로 체크포인트가 발생하여 디스크와 동기화되기 때문에, 쓰기 버퍼링의 기능으로써 리두 로그는 큰 관계는 없다.

그래서 리두 로그는 영속성을 보장해주는 역할로써 쓰인다고 생각하면 된다.

### 리두 로그 기록 설정

트랜잭션이 커밋되면 즉시 디스크로 기록되도록 시스템 변수를 설정하는 것을 권장한다고 한다.
하지만 이는 많은 부하를 일으키기 때문에 어느 주기로 동기화할지 결정하는 `innodb_flush_log_at_trx_commit` 시스템 변수를 제공한다.

### 리두 로그 크기 설정

innodb 버퍼 풀의 크기에 맞게 적절히 선택되야 한다. `innodb_log_file_size` * `innodb_log_files_in_group`으로 리두 로그 파일의 사이즈를 알 수 있다. 

사용량이 매우 많은 DBMS 서버의 경우에는 리두 로그의 기록 작업이 큰 문제가 되는데, 그래서 이 부분을 보완하기 위해 로그 버퍼라는 공간을 할당하여 버퍼링을 진행하여 조절한다.

기본적으로 로그 버퍼는 16MB이며, 만일 BLOB이나 TEXT와 같은 큰 데이터를 자주 변경한다면 더 크게 설정하는 것이 좋다고 한다.

### 리두 로그 아카이빙

데이터 변경이 많아서 리두 로그가 덮어쓰인다고 하더라도 백업이 실패하지 않게 해준다. 자세한 방식은 133p, 4.2.11.1 리두 로그 아카이빙을 참고하자.

### 리두 로그 활성화 및 비활성화

영속성을 보장받기 위해 리두 로그는 항상 활성화 하는것이 중요하지만,
- 데이터 복구 과정
- 대용량 데이터 한번에 적재
같은 경우, 적재 시간 단축을 위해 일시적으로 비활성화 시킬 수 있다.
```sql
ALTER INSTANCE DISABLE INNODB REDO_LOG;
show global status like 'Innodb_redo_log_enabled';
+-------------------------+-------+
| Variable_name           | Value |
+-------------------------+-------+
| Innodb_redo_log_enabled | OFF   |
+-------------------------+-------+
1 row in set (0.01 sec)

# LOAD DATA...

ALTER INSTANCE ENABLE INNOBE REDO_LOG;
show global status like 'Innodb_redo_log_enabled';
+-------------------------+-------+
| Variable_name           | Value |
+-------------------------+-------+
| Innodb_redo_log_enabled | ON    |
+-------------------------+-------+
1 row in set (0.01 sec)
```

비활성화 및 활성화 이후 `Innodb_redo_log_enabled`시스템 변수를 조회하여 확인하는 작업을 거치자.

리두 로그를 항상 비활성화 하는건 데이터 복구를 할 수 없는 것과 동일하다.
마지막 체크포인트가 10시 정각에 실행됐고, 10시 1분에 비정상적으로 종료됐다고 가정했을 때 모든 데이터 변경이 즉시 디스크에 기록되는 것이 아니기 때문에 몇몇 데이터는 반영되지 않았을 수도 있다(체크포인트는 트랜잭션 기준이 아닌, 페이지 기준이기 때문). 데이터를 복구할 방법이 없는것도 문제이지만, **데이터가 불일치하는 치명적인 오류가 발생**할 수도 있다.
그래서 리두 로그를 항상 활성화하되, 데이터가 일부 손실되도 괜찮고 성능을 더 높이고 싶다면, 위에서 언급한 `innodb_flush_log_at_trx_commit`설정을 활용하자.

---

## 어댑티브 해시 인덱스; Adaptive Hash Index

> innodb에서 사용자가 자주 요청하는 데이터에 대해 자동으로 생성하는 인덱스

### 구조
![image](https://github.com/user-attachments/assets/72e9badc-1ca1-4e88-9006-10ba8a48e427)

인덱스 키 값 - 데이터 페이지 주소 의 쌍으로 이루어져 있다.

인덱스 키 값은 다음과 같은 구조로 이루어져 있다.
B-Tree 인덱스 고유번호(Id) + B-Tree 인덱스의 실제 키 값

데이터 페이지 주소는 실제 데이터 페이지의 메모리 주소를 가리킨다.


innoDB에서는 어댑티브 해시 인덱스는 하나만 존재하기 때문에 특정 키 값이 어느 인덱스에 속한 것인지 구분해야 하므로 실제 키 값도 같이 저장한다.

### 이점
- B-tree 루트 노드부터 리프 노드까지 찾아가는 비용이 없어진다. 이를 통해 CPU는 더 적게 일한다.
해당 이점은, 다음과 같은 장점으로 이어진다.
- 더 많은 쿼리를 동시에 처리할 수 있다.

B-tree 인덱스에서 특정 값을 찾는 과정을 생각해보자. 
보통 B-tree 자료구조는 binary search 방식이기 때문에 매우 빠르게 처리된다고 생각하지만, 서비스 특성 상 동시에 쿼리를 보내기 때문에 몇천 개의 쓰레드로 실행한다면 CPU의 엄청난 스케쥴링에 의해 성능이 떨어질 것이다.

![image](https://github.com/user-attachments/assets/d7da5334-9360-4ca7-8e8f-28b03648101b)

![image](https://github.com/user-attachments/assets/7c9bf153-0d8a-4a9e-94ce-5ac5dcdfb1fd)

CPU 사용률은 낮아지는데 쿼리 처리 수는 늘어났다. 또한, 내부 잠금(세마포)의 횟수도 획기적으로 줄어든 모습을 볼 수 있다.

그렇다고 장점만 존재하진 않는다.

### 단점

첫째로, 디스크 읽기가 많은 경우 어댑티브 해시 인덱스는 아무런 도움이 되지 않는다. 
어댑티브 해시 인덱스도 메모리 공간을 사용하기 때문에 인덱스를 만들고 제거하는 과정을 거친다. 이런 오버헤드가 있는데 디스크 읽기 과정이 많은 경우 어댑티브 해시 인덱스를 사용하지 않음에도 해시 인덱스를 만들고 제거하는 과정을 반복할 것이다.

둘째로, 테이블 삭제 또는 변경 작업을 수행하면 성능이 느려진다.
레코드 말고 테이블 자체를 삭제(`DROP`)하거나 변경(`ALTER`)되었을 때 해당 테이블이 가진 모든 데이터 페이지의 내용을 어댑티브 해시 인덱스에서 삭제해야 한다. 그래서 테이블 삭제 및 변경 작업이 시작하면 어댑티브 해시 인덱스에서도 작업해야 하기 때문에 그만큼의 성능이 느려지게 된다.

### 성능 확인 방법

어댑티브 해시 인덱스가 도움 되는지 판단하는 방법은 `SHOW ENGINE INNODB STATUS \G`에서 `INSERT BUFFER AND ADAPTIVE HASH INDEX`부분을 확인하는 것이다.

defalut로 어댑티브 해시 인덱스를 활성화 되어 있으며, `0.00 hash searches/s,`이면 사용하지 않는 것이다.

`hash searches/s`는 어댑티브 해시 인덱스를 활용하여 키 값 검색이 초당 몇 번 실행되었는지를 의미하고, `non-hash searches/s`는 어댑티브 해시 인덱스를 사용하지 않고 키 값 검색이 초당 몇 번 발생했는지를 알려준다.

해시 인덱스 히트율`(hash searches/s / hash + non-hash searches/s * 100)`이 100%에 가까우면 어댑티브 해시 인덱스가 그만큼 잘 쓰이는 것이므로 효율적이라 본다. 만일 그렇지 않다면, 해시 인덱스가 점유하는 메모리를 보고 아예 비활성화하여 버퍼 풀에 메모리를 더 늘리는 것이 효율적일 수 있다고 한다.

---

# InnoDB와 MyISAM, MEMORY 스토리지 엔진 비교

MySQL 8.0 부터는 MySQL 서버의 모든 시스템 테이블이 완전히 InnoDB 스토리지 엔진으로 전부 교체되었다. MySQL 서버의 모든 기능을 InnoDB 스토리지 엔진만으로 구현할 수 있게 되면서 MyISAM은 더이상 사용하지 않고 없어질 것으로 예상한다고 한다.

MEMORY는 하나의 쓰레드에서만 데이터를 읽고 쓴다면 InnoDB보다 빠를 수 있지만, 트랜잭션을 이용하여 동시에 처리해야 하는 상황에서는 테이블 수준 잠금으로 인해 제대로 성능을 내지 못한다.
또한 가변 길이 타입 컬럼을 지원하지 않는 문제를 가지고 있어 향후에 없어질 것으로 예상한다고 한다.

---

[Real MySQL 8.0 1권 4챕터](https://product.kyobobook.co.kr/detail/S000001766482)

[망나니개발자 블로그](https://mangkyu.tistory.com/299)

[MySQL InnoDB의 Adaptive Hash Index 활용 - kakao tech 블로그](https://tech.kakao.com/posts/319)

[Pagination in MySQL - Aaron Francis](https://planetscale.com/blog/mysql-pagination)

[Real MySQL 8.0 4장(2) - InnoDB의 구조 - 기록은 희미해지지 않는다.](https://neverfadeaway.tistory.com/61)
